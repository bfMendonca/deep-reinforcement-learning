{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "\n",
    "--- \n",
    "\n",
    "## 0. Managing dependencies\n",
    "\n",
    "As this report shares mostly of the dependencies as the \"root\" repository forked from Udacity Deep Reinforcement learning, the instruction for handling dependencies are the same as stated at README.md. Please refer to the README at the root of this repository for the original file from which the below section was extracted.\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "To set up your python environment to run the code in this repository, follow the instructions below.\n",
    "\n",
    "1. Create (and activate) a new environment with Python 3.6.\n",
    "\n",
    "\t- __Linux__ or __Mac__: \n",
    "\t```bash\n",
    "\tconda create --name drlnd python=3.6\n",
    "\tsource activate drlnd\n",
    "\t```\n",
    "\t- __Windows__: \n",
    "\t```bash\n",
    "\tconda create --name drlnd python=3.6 \n",
    "\tactivate drlnd\n",
    "\t```\n",
    "\t\n",
    "2. Follow the instructions in [this repository](https://github.com/openai/gym) to perform a minimal install of OpenAI gym.  \n",
    "\t- Next, install the **classic control** environment group by following the instructions [here](https://github.com/openai/gym#classic-control).\n",
    "\t- Then, install the **box2d** environment group by following the instructions [here](https://github.com/openai/gym#box2d).\n",
    "\t\n",
    "3. Clone the repository (if you haven't already!), and navigate to the `python/` folder.  Then, install several dependencies.\n",
    "```bash\n",
    "git clone https://github.com/udacity/deep-reinforcement-learning.git\n",
    "cd deep-reinforcement-learning/python\n",
    "pip install .\n",
    "```\n",
    "\n",
    "4. Create an [IPython kernel](http://ipython.readthedocs.io/en/stable/install/kernel_install.html) for the `drlnd` environment.  \n",
    "```bash\n",
    "python -m ipykernel install --user --name drlnd --display-name \"drlnd\"\n",
    "```\n",
    "\n",
    "5. Before running code in a notebook, change the kernel to match the `drlnd` environment by using the drop-down `Kernel` menu. \n",
    "\n",
    "6. As an final step we need to use the Udacity Reacher environment: They are available in the following versions:\n",
    "\n",
    "    [One agent with visualization](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P2/Reacher/one_agent/Reacher_Linux.zip)\n",
    "\n",
    "    [One agent no visualization](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P2/Reacher/one_agent/Reacher_Linux_NoVis.zip)\n",
    "\n",
    "    [Multi agent with visualization](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P2/Reacher/Reacher_Linux.zip)\n",
    "\n",
    "    [Multi agent no visualization](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P2/Reacher/Reacher_Linux_NoVis.zip)\n",
    "\n",
    "    Just download the correction version and set the variables **MULTI_AGENT** and **VIS_ENABLED** according to the desired version.\n",
    "    \n",
    "    \n",
    "7. As an additional step some dependencies will be handled by using the next cell.\n",
    "\n",
    "8. For running locally with NVIDIA GPU and CUDA, it is necessary to download the correct PyTorch version. Please refer to the instructions at this [link](https://pytorch.org/get-started/locally/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install ../python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Start the Environment\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "The cell below act as an abstraction for using one of the many environment variants of the workspace. If the variable **'MULTI_AGENT'** is set by the user, this workspace will understand that we would like to solve the problem using the Unity simulator with 20 reacher arms, otherwise, the single reacher arm would be used. \n",
    "\n",
    "By enabling the visualization, through the **'VIS_ENABLED'**, the GUI of the simulator can be turned on or off.\n",
    "\n",
    "\n",
    "**NOTE**: Bellow we hardcode the location of the files for the reacher environment. Feel free to adapt it as needed in order to make this notebook run with the desired variant of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_AGENT = True\n",
    "VIS_ENABLED = False\n",
    "\n",
    "if 'MULTI_AGENT' in globals() and MULTI_AGENT:\n",
    "    if 'VIS_ENABLED' in globals() and VIS_ENABLED:\n",
    "        env = UnityEnvironment(file_name='./Reacher_Linux/Reacher.x86_64')\n",
    "    else:\n",
    "        env = UnityEnvironment(file_name='./Reacher_Linux_NoVis/Reacher.x86_64')\n",
    "        \n",
    "        \n",
    "else:\n",
    "    if 'VIS_ENABLED' in globals() and VIS_ENABLED:\n",
    "        env = UnityEnvironment(file_name='./Reacher_One_Linux/Reacher_One_Linux_NoVis.x86_64')\n",
    "    else:\n",
    "        env = UnityEnvironment(file_name='./Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64')\n",
    "        \n",
    "        \n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "print( env.brain_names )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( env.brain_names )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Agent Setup\n",
    "\n",
    "Below we can configure all the necessary parameters that are relevant for the agent training behaviour. \n",
    "\n",
    "| Parameter             |Description                                                                                       |\n",
    "|-----------------------|--------------------------------------------------------------------------------------------------|\n",
    "| state size            | Size of the state the is observed from the agent                                                 |\n",
    "| action size           | Size of the state the agent uses to interact with the environment                                |\n",
    "| random_seed           | Seed used for internally generate random variables                                               |\n",
    "| buffer_size           | Maximum number of entries for the replay buffer                                                  |\n",
    "| batch_size            | How many replay buffer entires will be used for each learning                                    |\n",
    "| gamma                 | Discount factor                                                                                  |\n",
    "| tau                   | Smooth factor used for uptading the local networks parameters from target network parameters     |\n",
    "| lr_actor              | Learning rate for the actor Network                                                              |\n",
    "| lr_critic             | Learning rate for the critic network                                                             |\n",
    "| actor_weight_decay    | L2 Weight regularizer for the actor netowrk                                                      |\n",
    "| critic_weight_decay   | L2 Weight regularizer for the critic network                                                     |   \n",
    "| learn_prescaler       | How many steps the agent should run between each learning                                        |\n",
    "| learning_cycles       | How many many times the agent should run the backprop. proccess after **learn_prescaler** cycles |\n",
    "| noise_initial_gain    | The initial gain applied for the noise added to the network output.                              |\n",
    "| noise_gain_decay      | Factor to multiply **noise_initial_gain** for each step. Makes the noise gain decay as the proccess goes. Keep it 1.0 to disable this behaviour |\n",
    "| sample_every_cycle    | For each **learning_cycles**, if the agent should sample from the replay buffer. If false, the agent will try to run the backprop **learning_cycles** in a row using the same initial sample.                                    |\n",
    "| gradient_limiter      | If the agent should, or should not, limit the gradient for gradient ascent step                   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]     # reset the environment    \n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "agent = Agent(state_size          = 33, \n",
    "              action_size         = 4, \n",
    "              random_seed         = 2, \n",
    "              buffer_size         = 100000,\n",
    "              batch_size          = 128,\n",
    "              gamma               = 0.99,\n",
    "              tau                 = 1e-3,\n",
    "              lr_actor            = 2e-4,\n",
    "              lr_critic           = 2e-4,\n",
    "              actor_weight_decay  = 0,\n",
    "              critic_weight_decay = 0,\n",
    "              learn_prescaler     = 20, \n",
    "              learning_cycles     = 10, \n",
    "              noise_initial_gain  = 1.0,\n",
    "              noise_gain_decay    = 1.0,\n",
    "              sample_every_cycle  = True, \n",
    "              gradient_limiter    = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Agent Network representation\n",
    "\n",
    "In order to expose the network architecture choosen for the project, we implemented the method __repr__() into the ddpg_agent class that print both networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor(\n",
      "  (fc1): Linear(in_features=33, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=4, bias=True)\n",
      "  (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "\n",
      "\n",
      "Critic(\n",
      "  (fcs1): Linear(in_features=33, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=260, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print( agent )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Learning proccess\n",
    "\n",
    "The method \"ddpg\", described below, controls the learning algorithm that the agent will perform. As the parameters for this method:\n",
    "\n",
    "| Parameter | Description |\n",
    "|-----------|-------------|\n",
    "|n_episodes | This defines the maximum number of episodes that will be run in order to train the agent\n",
    "|max_t      | When running the simulation, this value address how many iterations the simulation should run before be terminated|\n",
    "|print_every| This controls the size of the deque used in order to smooth out the output and also when to print an output informing the training performance |\n",
    "\n",
    "### Description\n",
    "\n",
    "As a brief description for the learning proccess, at the beginning of each episode the environment is reseted in order to place all agents in a given initial state. \n",
    "\n",
    "Then, for **max_t** iterations the simulation will run and the follow steps are performed:\n",
    "\n",
    "**1.** The environment states are used in order to infer the actions using the local Actor network at the agent.\n",
    "\n",
    "**2.** The actions are passed down to the environment in order to update what each agent should perform given it's present state. One important note is the that the \"act\" function countains a \"implicit\" parameter, **add_noise**, that by default add an random value to the network output. This will allow the agent to explore the environment and add new values to the replay buffer that would not be achieve otherwise.\n",
    "\n",
    "**3.** After updating the simulation the current state, action, next state, rewards and if the agent achieved the desired goal are inserted into the replay buffer. Note that for the multi-agent environment this will be done for each \"tuple\" for these variables. \n",
    "\n",
    "**4.** Finally, the agent **step** method will perform the hard work of adding up this tuple to the replay buffer and at each **learn_prescaler** samples to perform **learning_cycles** back propagation cycles to the network. As stated above if **sample_every_cycle** is True, each backpropagation will update the \"target\" version of the Actor and Critic networks using **batch_size** samples from the replay buffer sampled for each cycle. \n",
    "\n",
    "One important parameter for this step is **tau**, which will smooth out the Target network parameters before applying for the actor and critic network. This proccess is important to make the larning more stable as the most recent result of the gradient ascent will be only contribute to the \"local\" parameters of the networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmendonca/workspace/udacity/deep-reinforcement-learning/p2_continuous-control/ddpg_agent.py:170: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(self.critic_local.parameters(), 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 32.25\n",
      "Episode 200\tAverage Score: 33.35\n",
      "Episode 250\tAverage Score: 34.23"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABNL0lEQVR4nO2dd5xcV3n3f8/0vr2pS1azZBtZloWNwRUbYyCmmJiWmARiwASHhPBCwksCb0ISSICEhAAmOAhwTDPYJAHHBYFN5CbZsizLRcUqq7J9d3q5d877xz3nzJ3Zmd2Z1c6uvPf5fj76aPZOuee233nO8zznOSSEAMMwDOMcXPPdAIZhGGZuYeFnGIZxGCz8DMMwDoOFn2EYxmGw8DMMwzgMz3w3oB46OzvFihUr5rsZDMMwLyt27do1LIToqtz+shD+FStWYOfOnfPdDIZhmJcVRHSk2nZ29TAMwzgMFn6GYRiHwcLPMAzjMFj4GYZhHAYLP8MwjMNg4WcYhnEYLPwMwzAOg4WfYc4ARpI5/PyZk/PdjFllx8FhHB5OzXczmCqw8EsyeRODiex8N2NWef5UHKmcMd/NYOrgBzuP4ZY7nkRyAV2vD9/xJL7x0MGm/Ha2YCKeLTTltxXj6fxpfT+TN/Hb33gEOw+PzlKLZg8WfslXfrkfN3ztkfluxqwxkSng2n98GJ/66TPz3RSmDsZSlsik8wtD+JM5A2PpAtJ5sym//xf37MWN33i0Kb8NAAcGEzj/r+7HY4dGGvreA/sG8OBzAwAsw+vxl0bxTw/ub0YTTwsWfsmx0TROjGewUFYk23ciDgA4MJSc55ZMjxACOw4Mz8m5PzqSxi137EK20BxBmikTGct6zRWKNT+z/flBHBg8868nAJwYzwCY+nhOh+dPJfDcyTiOjqSb8vsHBpMQAnjw+UFsf2EQdz91HMVi9fvz6Egal35hO46NpvH+7+zE+7btxP6BBF6Sbq6H9w/j4Bn2HDpa+CfSpaHiRKYAoyiQbdKNOtc8e2ICALCqMzLPLZmep46N413/9hgef6n5Q+IdB4fx82dO4dDQmeV7VsKfmaJD+tiPnsZtTXKdzDbHx6TwG83pYPvl7//qxcGm/P5APAfA6mw/+v3d+OgPduPm71avF/ZvvzmEo6Np/PyZk2gJegEAf/rjPXhpOAUXAT63Cz984lhT2jlTHCv8z5+K4/y/ug97j1sCOS47gdnwGwoh8I1fH8Qh2csfGkri/duemFMr8xl5XGG/e872OVMG5UM2mjo9n2o9jEuBTTTZP9wo6v6rdY+YRYGxdB7xTH2uoOPjmXk9xn5l8Ruzb0il84a+V379wlDd38sWTPz9/zxf13kZiFvxvv2DSUxkCtiyvA0PPDdY9fq8cCoBAOiO+RHyWc/b08fGsePgCJa2h7C8I4QjtpGJYRbxxn9+GPfsPl5322cbxwr/0ZE0igLY0y+FP2PdSLPxsPSPZfC3v3gedz9lXdhdR8bwwHODODwyd1am6tCa5WOdTeJSjGca2CyYRfxm/3Bdn1UCe6YFUbXFX+N6TWQKEAJI5Oq7Py/5u1/i6i89NGvta5SSxT/7wq/cSJ0RH3YcHEG+zn08eWQMX91+EL98fvpRgrL4AWBFRwjvuWg5AKB/bLJr6YUBS/jTeROpnIEty9sAWM/9ys4w2sO+MqPm2RNx7D0ex0Mv1nfPNgPHCn88az34yvdWsvhPXxCePDoGoPQw503rxkzl5kaEUzkDh6R/sZaQVOOfH9yP7z5yuEmtqs2ETfi37TiMu3b1N/T9+54dwHu+9VhdqYMqU2OuhP/4eAYX/+2D2t9bC3UOsjVETAlHsoH781Q8CyHEvFj+2sffBFePcvO8bmMvMgUTR0frM6iG5TncP1Dyt2cLJv7z6ROT4kuDiSzOWRzD2p4IPnDZWVjWEQKAMssdsDwESjtSOQOZgokLlrdpy39VZwQdER9GbRlCj8qA8aHh+fP7O1f45YN2aCgJwywiIR8otR0ABuNZHBttPHj05JFy4VcBrrlKrdx7fALqPp7KZ1zJT3cfx8+ePtGkVtVGC3/WwPcePYI7HqtaQrwmIynLOhtO5qb55OQO/juPHMbn732+of01wv6BBE5OZPUIrBZa+Gtcr7G0GpFOfw+ZtiDkjbc9inM/c9+cB7OPNzG4q4T/NWus9UUODKbw3n9/XGfT1GJU3h/2APnt//sSPnLnU9pqVwzEs1jcGsR9f3wZ3rl1GZa1W8J/tEIP9hwrXdfxdAEFUyAW9GLzMsvqX9kVRluo3OJXwn9wMDlvySTOFX5pBR0aTpVZ+fYH69P37MX7tzW+AMyTR8cBlPzJyuKfq1S9Rw6NwEXAxkWxhh74iXQBg4npxXO2UW62ZN5APFvAifHG5lOoazaRmWzZCiHwoe/t0q4gvS/5nXv3nsL/PHtqxm2fDnVvTdUp5Y2idsnVFH4pHPWMSFO2+0wFzIfm+Lo209VzfDwDj4tw0ap2AFYA9lcvDOG+Z6cRfmXxDybQP5ZG/1gaP5BB18rzMxDPoScW0H93hH0I+dyThP/5U3H9Wv1GyOfGhSustq3qDKMj7MNYOg+zKGCYRew8PIaA14V41sBwsvlxrWo4V/hlkOzYaLps4pZd+I+MpPHCQKIs+6cWqufO5E08d9K6GbSrR978yTly9ew4MIJzFregNxao28cvhMB4pjDnAgEAE/JaJLMG4hkDA4ls3X5bYGrhzxRM/GLvKTy83woCKotfuT9GU3lkmxgHUSPIqc6rvd3TWfzJOnz81UaWQ7aO5969J/HxHz097e/Uy0+e7C/zfeeNIgbkM9UMV8/xsQz6WgNoDfnQGfHjF3utGc+VKZMT6UKZRa1cPYdH0njXNx/DFf/wK+26sVvk2YKJiUyhTPiJCMvaQ9oD0D+WxkSmoN237WGfPsdhnwdvekUfLl/XhfOWtKA97IMQlpvxxYEkEjkDbzxvUdU2zxXOFX754BeFFYGv3A4AJyesm3fP8XFMx8d/vAe33LEL+05OwCgKRPyeScJvt/gPDSXx+Xufx46Ds5u/ns4beOrYGC4+qwMBn7tuV08iZ8AsCqTz5pwHPtV5Gk8XkCmYEKKUVVEPSgyrCb/q+NSDXRncHUnlG3KHNYq6n6ay+O3trhWTGU0pV1ARBXPqTlGNZi5c0YYLZKBxxGZZ3r9vED/a1d/wdf7Z0ycmfefpY+P4kx8+jc/+5z69bSCehRCW5dssi39xaxCAZVGrUdCBoZLrZDydx9a/eQD37yuNAkblOTCLAkdH02gJ+tAastIv7Za3yjLrjvrL9ru0PaQt/nd+81F8+f4XkS4Y8HlciAY8JYvf78aqrgi+/XtbEQ140R6xfmc0ldf34atXdwKYLPx/8/Pn8JMnG4txzQTnCn+mALeLAABPHhnX2wfjObx/2xPY0z+uH8jdR8er/EKJp4+N48e7+rHz8Jj2P25YFNMjBeXqsT80//zLA/jarw7iXd98DDtlTKAWQgj8z7OncNPtj+P923ZO6S9+4vAYCqbAJWd1Iuh1123NjqdK4jPXVr86z8ovDJT8uLVIZAt6Qk1yKotfHr+ymO2unmJRYLTZwp9Rrp7aQ/qJjM3arCGUY7bg4HR+fnWf3XL5anzlnecDsGoBKVQn9NIUcxnyRhEf/9HT+PqvrXkDR0fSuPXOpybVE/rmw4cAAD5PSUqUwbS8I9wUH/+J8QwWt1o+91VdYb19PF3QwjqSyiNnFHWSA2AJr8qzjwY8eOj/XI5ff/wKuF2E0VTp/KjRit3iB4BlUvhTOQPHRjMYSuaQyZsI+dwI+Txlrh47HWGf3r+6Nqu7Iwh63Tg4WH4NbnvoEP7kh083PSbTNOEnogARPU5ETxPRs0T0Wbn920T0EhHtlv82NasNU5HIGljXEwUA7DxSmjj0xOFRPPDcIL77SCnA+HT/+JS/9Q/3vQDAGk4rwVrfG5UpeEJb/GoInsmbuO/ZU7hsrRWcev5UosqvlvjWb17CB767CweHknh4/xC27Tg86TMf/O4u3PHYEd1JbVlhZRbUK2rjGbvFM7c1i5Q75IRN+O2vKzHMIi79wnZ8R2YgTeXqURb/SCqPbMHUE/TiWSueYMpJe7VmZZ4uE7Pk6rG7IqbL7FHuh0jAo0XHPuJQbanlZhBC4NY7n8KPdvXjX355wPpOMit/29r38fEM/uwnz+AXe634iF3gT05Y125FRwg5w5zVEW2xKDCUyKEnZlnRKzst4VfB14ND5dlsY7bzNpzKYcvyNvg8Lrx502KEfB60BL2Tgq9qtFlN+LOFos7aS+cMpPMmQl43wj43RuRvhHyesu+124Rfnb+I34OVneGyzB57UP6uJlv9zbT4cwCuFEK8AsAmANcS0UXyvY8LITbJf7ub2IaaxLMFLGoNYHlHSN8s0YAHL8ro/sMyGLi4NYjdx8Zr3rzJnIH/PTCM3lgAQgB7+scR8XuwuDUIoyiQypt6uKseyO0vDCKVN3HzpasQ8rn1RC/Auvj2gFE6b+Bff3UQr1nTiV/96eW4Yl03dhwcKWtPsSjwwHMD+NULQ+gfS6M76kfI50HQ24Dw2+IYQ3Vkx8yURLaAt399B546WhrlaHG07Xcq4U/lTIylC9hx0MqOSOSmEn7rvbFUvuz9ZK6gH1SgOUFIYHpXz717T+LRQyXDo9b1sgvYdJMMlesr7PMg4HUj6veUjTiGq2S32Dk8ksa9MuCtLGT1fdVx/nhnP+58/CiuXN+Ns/tiOrMKKAnnso4QigIw6uxUv/nQIXz67r1TfmZczrDvkm6YVV3WzPQ3n7+47JhUbMEu6KOpPBa1BnH3LZfgz65br7d3RnxVXT1dFa4e1ck8IN1HqbyJTN5E0OdGyO/Rwh2uIfwjqbwOvIf9HvS2BPS+gPI5RN9/vLkzfZsm/MJC3Vle+e+MKYQTzxYQC3hxzqIWvW1xa1ALwCl5816xvgvDydozJvccG0dRAK8/txcAsPvYOHpifv3ATGQK+iZUvf0v9p5CZ8SPi1Z1WL2+bch9/75TeP0/PayF7z8eO4rRVB4ffe0aeNwuXLK6A8fHM2XZBWPpPIyiwLHRNI6PZ7CkzfJ/Brzuuq1ZuyvBfjPONo8cHMETh8dw20OWi0AIoQXZ3rcen0L41SQm5fJKVqTifu6/9+EPvmNlY9kt/kp3id3v3Sx3j2rTcDJX1Xj4xF3P6HPhotrpj2PpPLxuyzU5vatHWvx+S4A6Ij7dyRWLQr+utPifODyK9337CZ3ldN25vRhMWHMBlICq83R0NI3eWADf/N0tWNsTKTuXJyeyiPg96AxbwlmtUx2MZ/FERdXKHQeHsf2FqSdXqU6rU/rNLz6rA+/cuhQ3XbwcAa9LH1Mmb+1TXXPDLGI8XUB72IcNi2JlVnnlBCv1nEYD5QK+cVEMAPQoJ503kM4bCPk8CNvcO6GK2fJtocmunojfg66Iv8wgUMZXxO/BsSoTxWaTpvr4ichNRLsBDAK4XwjxmHzrc0S0h4i+TET+Gt+9mYh2EtHOoaH6p2XXSzxjIBb0YuNi62LGAh59geycu9jqGOwWjZ2nZGD42o2W8A/Ec+htCeig0US6YAvuWg/Ncyfj2LysFW4XYVVXpGy4d3LCCoypG+Lh/cNY1xPFBcut9LBXyaDQ/x4oVQ1UKZj9Yxkr8NVmDXuD8mbM1pFZYbeGm2nxPybTCx94bgAjyRxSebNsiAsAYZ97auGXwndiIouRZE53BOoYnj+V0KKiznkia2A4YT3cXVE/kjmjzK87E+EfTGRhTBNoVYHHgikmjUhU9oiiPeyvGdwdSxd0QFOJR7Eo8K5vPor7KtJRtTshoITfr338Kq0QmCz8395xGA8+P4gv3f8ilneEcMHydhRMgbF0QX8/J8/TsbE0lrZb7ekI+8uE89REFr0tAfi9Ln2clXzll/vx+99+oqLd0ycWKDeVssYjfg/+9q3noSPix+ruCPZIt6y6nqpdY1JUOyKTn/H2sK8sBpIumPC6CV53uTx2RPxY1BLQz1s6ZyKtLH5bR1Lp41fBX+XqcREQ8LrQGbU6ZGWYqfTvtT0RjKcLTfXzN1X4hRCmEGITgCUAthLROQD+DMB6ABcCaAfwiRrfvU0IsUUIsaWrq2tW21UsWrMZYwGPtvhbQ75JPXx72IdF8mGzuwXsPHV0DGd1hbGuN6q39caCiEmLfzyTt6VzGiiYRRweTmF1tzVEXdUZRv9YRl/kuC21EbBGJt2xUt+4qjOM3lgAj700WfiTOQNHR9NaINQNWM/s3TEZ3O2O+k/b4k/lDOy2ZUrZeeylESxuDaJgCty9+4SeSas6SgBY1xstc/V86Hu7yiZ12cXhmeMTk4K76byJ8XQBiWyhLJPqJVkyY2lbEMmsUXZN7edoOJkrc61UwzCL2Pq5B/GRO5+a8nMJWxJBpbvH7vePBjyI+N01O+nRVB7LOixXg3IJDCZy2HFwBNsr6tWo86PqNFmuDGtfqlNf1h7C4eF0WcfVK33aeaOIy9Z26ayWwURWnyslqP2jaSyVBkZHxIdkztD38MmJLPpaAvDLgG81i//gYAqJrFGWtpvMGUhkDT0yOjmRmZQOWin8dl5/Th+eODyGA4MJ3U4l+Mpw6whP/l5nxD/pXgh6q9e42mDzEKTy1kzdkM+NiM3Kr/TxW/u1RD6VMxH2e0BE6Iz4YRaFFnz1LCgtaWaSxZxk9QghxgFsB3CtEOKkdAPlAPw7gK1z0QY7qbyBooBl8cvhW1vIi2jAq18D1oOgbpSRKlawEAJPHR3H5mVtaAl6EZAWTm9LydUTzxTKJnAdGUnBKAqs6ZHC3xWGEKWp4Mp/qx7eeMZySSmICH2tgTILyx6MFQJYbHP1APVZs+OZPKJ+D/paAqdt8f/HY0fx9q/vmGSxxLMF7DsRxw0XLMGqzjAeOzSixVp1VgCwrjemM0OEEPjl84N4wla50x7cfKZ/Qp8r9Vv2AKRd0FUsZUlbCImsodP7gHKr9APf3YXL/n77lG4HdU7VsL8W8WxBBx4rJ8fZ/24NeRHwuqt20oZZxESmgOXyd9TxKndfZamKZM6A103we6zrb1n81rGqUc9Fq9qRN4tl2VN2H/OV67t1cHMwntPfzxZM5I0iTsazWCLb0xkp+bABafHHAnr/uSr33xHZCdtHPKm8lVKcKZjIFkxc/aWHsG3HYWQLphbBqYT/xguXwusmfO/Ro/p6qudEXWvlb7fTHvaVdULKfVONc6SHAChZ/CHp41dUWvxqH2PS1aNccMpdpTrlCW3xW8LfSEpzozQzq6eLiFrl6yCAqwE8T0R9chsBeDOAqaM5TUANv2MBrx6+tYR8iAWtC6KybfpaAvqmrpaO1z+WwUgqj03LWkFE2mLqbQmiVbqNxm2unmTO1MGn1V3WxT1LBqeUKNnr1lh/G7pdioDHXSZUlYKifPzKaqnH4h9PF9Aa9qIrGjjtrJ7j4xkUTDFpvz/a2Y+iAF65qh1re6K68iFQEn6vm7CkLYh03nr4MwUrOF42u1qeG5/bhV1HrfRVotJoSQXQjo1myiawqVjK0vYg8mYRJyZKx6nOp1kU2Ht8AvGsgVvvfKpmfMTemdYKtgohEM8YWCWDgpX30JBMG7x+0yJcs6HXislUsY6VRag6EOXqUpOJjlQU/0tmS+ICAJ1hq1aMWRQ6O+cVS1sBACcmSsIfz1iZbr/82GUVFn9OW8yZQlGuW2GNnACUGUeGWcRgYmqLP1sw9bm3p7KqDj2RNXBwKIlkzsDhkTT+dfsBXPeVhyGEwHAyZ7lO/JOFuTPixzUbe/GfT5/Q13MiU4BhFnWnVM3Vo7apTkKJeTWUh4BIWvx5E0Fvycfv87gmuYgAy403Il094QrhV52ZehZUtuGjh0ZwzZd/3fBiMPXQTIu/D8B2ItoD4AlYPv7/AnAHET0D4BkAnQD+uoltqIoKuClB/dxbz8UfXbVaW/znLmnFkrYgVvdE0KYi8lWEX4n4ejk0622Rwh8LlAV37emc6jtndVtioDIFlBuislJlPFvQbiOF3+sqe5iGEjn4bDfbktYK4a/H4k/n0Rr0oSfml8I98ywXdSPb2/jjXf34q//ah9es6cTWFe1Y2xPBkZGU/qxyqbUEvWUWpBqq22soKYFY2xvB3uNWBlR31I+MtEbTMrjZP5YuO/aXhlPwugndUes62Yt7qc8dG00jZxRx/rJWJLJGzVhDNl86tkcPVn8wc0YRebOoc82HE9VdPZ+67mx8+o0bEPC6qvp1lduppyUAn9ulOxpl8Z+YyJZ9zy4uANAZ9UMIS9jUPlXsym5VxrMFRAMerOqKgIi0i3Egni2z+FXgcansiNojpWdkKJlDUVhtVT7+SuG3Fzorz7QqCb8qpDacyOHgkHWfnIpnMZTIoSvih2U3TmZlRxhj6XxZhz+eKcUoqln8HTrrRnZu0m9fjVcsbUXQ68Z5S1pRFFbMJGTz8YdrfK897MVoKoek7dp0RctTbVVwd40U/u0vDOHFgWTZtZwtmpnVs0cIcb4Q4jwhxDlCiP8nt18phDhXbnuPLfNnztDCL4X+inXduGB5O2LSx7+4NYh7PnwJ/vi1a+F1u9Aa8lYN7qrgmFrspK8lKP8PIOxzw+0iS/htrp79g0ksbg2WbhS/B9GAR/vV1UOdyBp6WG139QDVLP4slrQHdWejXD3KahmM56atXDmWLqA15MWV67uRyBo6Ze2Ox45Myr6YjsEq0/V/+lQ/1nRHcPt7L4TH7cKaniiKAnhKzjtQo5RYwIt2mwVZqlFTEgjlkji7N6YfGjVimMgUtID0j2XKfPxHR9NY1h7SsZzDw2ltlarRiUrnfcO5fQBqz7Gwdyi/frF68kHcZql73VTV1eMiyxUDqCysKsIvBaFdxqFUx2fP/LBnedndCYDNIk/lMJzMI+B16RjTyYly4bcbGSGfBxG/NTFJWczZgoljoxl9XAB09s5wMqd/z7L4J7t6dh8bL5uAqITfMIu6g0hkC7po2nAyp++ng4MpDCVzVd08irDfowVZn79UHv1jGQS8LrRXSeDosM2sBaa2+Luifuz8v6/FmzctKvusiqfUchG1ywB4KmfoeEBXxDJAVGc8ni5Y2VARH3xuF546Oga3i/S1mk0cOXNXuQ2iFYKqBHZJWxAdEb/2kXeEfWUW/97jE/jRzmM4OJRER9inRwXKJ9oTC4CI0Br0YjxT0Cl6SWnxV17Irqhf+9V13ZqcYRuZVAi/11W2UthgPIfuqB9L2oJoC3n1zReQN+/f3fs8bvj65PWEi0WhH6qJTAGtIR8uX9eNRS0B3PHYURTMIj77s3341E+faWgSTqXFXzCLePLIOC5Z3amHwSrG8ZCsoaOEPxr06qH3SLI0xb3SMnQRygLqKpNpLJ3X++0fSyOdN3XsBbA6eXXd7VP/lZDvlyOyN5xnCf+LA1MLf1vIix/uPIZn+ifPpladVUvIh+4qLrShRA4dEb8O/gZrCL86B21hLyIBT5mrR7k87GWfK4VfWe77TsQxlMihM2LN84gFPBiwC3/G0MaP/m7Uj4F4VrdBWfxeN+n73e4qUUH53lhQd6pZwyozkcwZePvXd+BTd5fWgS7FZUrHbVn81nkfSuZ0h3lgMGFZ/FMIvxJVFctQ7To8ksLy9jBcrskjhfaKUX26YCJYQ8ABq3OxW+H2rJ5aHUZH2IeCKTAQz+k8/1jQA5/bpV2A4xlrZrEabRUFcFZXWOvQbOJM4a9w9Siu3tCDj79uHc7ui5Vt76jIt/3eo0fwibv24Mkj49pHDwBvPK8Pv3/JSu2qaAl6yyz+bKGIA4NJrKkQ/s6IX4uldvXImaXqd+xUWoaDiRy6owFcsLwN58tysEDJ1XNwKInhZG5SOuEtdzyJrZ97ENmCibF0Hq1BL9wuwju3LsNvDgzj4f1DyJtFvDiQLEsfnQ4t/LJzevZEHJmCqSsWApaLy+0iHBpK4VVndaBbikjMNtvUnntvn0eRkD5sZXECJYvfng10bNQK7kYDXi1oV67vLhNFVWddnc8Dg0n0tQTQ1xLE4tagXl2pEjVC+Nu3novOiB8f//HkomeqE48FPOiJ+XEqnkUiW9Cjr0HptlAEaky4U+egPWxZ/Ambq+fiszoAlAd4K1095y9txfreKL5434vYP5jQwtnXEiyz+BNV3IrdMT/2DyZ1CmimYKJ/LINFrUHdYYV8bgS8Loyk8tg/kASRdX2Vxf/jXf3Y+rkH8PhLIyiY1kxp5ZrUtZNsI7NkzihZ/Im8Hg0fkPdxZ2Rqix8oz6AaS+fx0nAKKzpDVb+jEzGyajEcA6FpxDZckb6pLf4abhnVuZycyOj7j4jQYcu4mpCjbqBkRK7vjVX5tdPHmcKfLXf1KNrCPnz4itX6hlZ02ibAqO8XhbXyjvLVA8A5i1vwF2/aoP2P0aDXyuqx+ThzRrGqxa/8v6ptqZxRJhx2At5S8SshLKu9O+rH/7v+HNz+3gv155TwK2PdXkFxIJ7VszOHEjlp8Vvn47UbegAA395hpVD6PC5sq7JAy2gqP0kYUzkDKSmKytWzU7qKLlxR6pT8HjdWSNH9g0tXacu1JejVQ++RZK5s4pA9LTYa8GofM1Bybykh83lc2uIP+dyWaPo92LKivSxt932vXmn9vs3Vo67Put5oTeFXHUVvSxA3XLAELw4kJs1H0PdZ0IueWAAD8Sz+8YH9evQ1mMiWpeqqCXeK4+MZ7DgwXLL4Qz5E/V6dOjkQz2HjIqv64+GR2q4ej9uFz/7WRhwfz2Dv8TiuWNcNwPLDKx+/EALxrDHpmeiOBnRcisgyXsbT+bI5L0SEjrBlHL04kMCKjjCCPrf28e89PoGxdAH//r+H9bU5u88arVVmYgHWvXlsNINowIOMDPAD1hKHI6n8tK4ewBJ+9RwPJfM4NprBis5w1e+oc6VchFO5ehT2SVpBn2d6H780BosC5fEXm9E3nrELv3WMlUbobOFI4Vc+0kig9nDOTkfYX5bOabec7RZ/JWGflZ6XM4qw9yWThF9efLMo9DA+kTPKhMOO31MKAiZyBrKFYpmAKCpvXnvqnpotCqiqhqUg19qeqFXE6sUh+NwuvOHcvqqujH/dfgBv//qOsswXu6WlOqfHXxrF8o6QtuoVW5a347wlLbh8bZe+FrGgF2GfGz6Pqyy4C5R8+yprxS78ylWkLP413RHEswaGEjkEvW5sXdmOt12wBD6PSz9cG/pi2CInxmXkDOeDQ0ms6Y7q83BwKFm1RLQKHga9bnRGrGF55ZrB9liSJfw5vHAqgWFZ3GsokSurABnwusqK6n3tVwfw/u/sxGgqj6DXbZVfCHgQzxj6Wi7rCGJpW7AsCF0p/ADwylUd+Pf3Xoif3/oa3HrVGgBAb8yvO8q0nEhXOZfF7k7rjloTzKyOt/xzXVE/+kczeGEggbXSjadcPafkPh7eP4yemB9fe/dmfPL1Z5dVsLXPzVBzQF65skNvC/ncePqYtcBQZdVMO+q4R5J59ESVi2sCebOIFR3Vhd/vccHtorJaWrWCu4oyi9/r1n/X9PHbOspy4ffZgrtWggUAnYCwvi+KZuBI4c8aJtyuyTPzatER8WEsXdCZLna3w1TCH/J5kMwZyBtmmYVUzeJP5IyyCRtWbfrqrh6/tPiFEFPmNQemEH6771pZtV3yZnO7SK8buro7ghUdYQwkspMn0yRziGeNssCi/RjU54+OprWY2vmbt56LH3/wVSAi/TDEApaPs1PGVcpr1JTiH5GAFXhUcy6U20ctAKKypY6OphHyufGFG16Bz/zWRgBWHv9tv3MBfvTBi0vB3YKpO9FFrdZ5OGdxDEZRVF0UW1mhSviBybO7ddpw0KrLkswZ2CfXajgVz2I4WW69WumcpXOs0lEPDSW1q6Aj4sdIKqc7uEUtQYT9HqRtwqkmCVVyxfpubFhUsiB7W4IYSuZQMIs1jYz3v2alFvmlbVbRtUR2svBftKoDTx4dw+HhFNZJ94Ry9djdV+csasFVZ/fg4rM6tCvUanOp/ftOWOdoi22EuHWlNe+gryWAa8/pnXRsCnXcI6kcYkEvIn6Prr5bS/iJCGGfW8cZ6rL47SUayoK7tbJ6Ss+/fbJXV9RflsffIu9ndQ9uYIt/9sgWigh46j905XqwZ5h0RvzweVx6Alg1wn430nkTebOorczOiF/n+CvUw28v1lYW3K3M6rGlyak2tVeZkVg5+9Du6olnClocn5di1GnLcb5wpWUJn90Xw5K2IITApJWxSiUSJq9CBJR8/Om8qR8MO24X6XK+EZ8HF6/q0O6g9ogPI6lc2Vqlan+JbEFbdsrqX9wahItKmS7qIT8xkalqhV2zsRdhvwcuF+k0yspg+rUbe3HRqnZ8+p69k8obKDEL+Fz6vB0cTGHLX9+PR2R65wm5UpRKkwVKo4IXTlmuIWXZAdb1KphCz6ZV4v7siTjawlabuqNWPriqgNnbEkDI59YjkGJRIJU3ysSlFqqw4FAip42ZynvN73HjN5+4El98+ytw3pJWZAtFJLIFRP3ln7tyfTeMokBRlPLQ/VWesXMWl2a+xoJeXbrcLvyqlPJ5S0qffcv5i7G2J4Jv3XThlD5+ddwFUyDoc2NtT0THC1bWcPUAVoeRzFmlujPTBHeBcoEP+ty6w6l2nwPl8wfsnbLK9hFCWHNp5L1344XLsO33t06qEDpbOFT4zYYi5Z26tG0pw+S6c3vx9F9cM8l9YSfs9yCdt2YEqh6/MrALlIT/gBSXgNdlCb/NYrQTkJZUtmBqIamWpuZ1u+CRPiYiVMzSNLSP/Xlt8ZceqK0rlPBHtRulv6JwlBLKfSdLo4fBxGRXj2VBTf0guVyEO2++CFedbcUXVP2XsVRe+2rV/hLS4gcsK9TncSHgdaMt5NOphsqfKwSmHbYH5YzZiYoRlsftwj/eeD6yhSLurZihm7W5epRh8MihYQwn87oj3H10HGf3xeDzuCY9wE8ds6qT9rWUtqsOPStHc0r4BxM5PWLskjn5yirujgYQ8nl02mpaLmRTjxtT7VsFnYHJ95o6H2+7YAmCPhcyBdNytVX8/uZlrfq8KfeQ35ZNpe7/85e16m2tNovfvjqdWRQI+9xYbRtNX7m+G/f98WVlI5ZqlGXbeN342DXrAFjndioXUdjvQSpn6BHXdBa/fT8hn0d/vtZ9HvJ59PW1fzcW9KBgWoXzjKLQBmJL0KsnkjYDhwp/sSHhV+maY+m8nI1plVGY3g/oRjxjlYdQD261nFyV2XFQBtEWtQaRyBqYyBQQ8Lr0kFmh2p4ziiXhrzIjESiJ3tm9sTLhj2cL6G0JwucpVTS0C//mZW348+vW462bl+ip+ZWLo6iOSY0YgOqunkzemPZBqqQjIl096YKeIRq3+fhVwPuajT06574t7NOLaKhODagdcFOo8tUqw6TV5u7obbFKd1cufmN39ajr97RceHsiY9X539M/jk1yhmxvhfA/KRffWWZrpxqhWaOPUpAcKN0/Srz2nogjGvDIVMKSxa8s53om/ajO6NREtmbCg52g1w1TlhqvdPV43C5ctrYLAa9Ln3v7pMIr13fjng9fUiZm1Vw9avS0uC2I9rAPRNZ+K2MWtbB/LuB145LVnbh2Yy/OW9JaNZVTEfZ7kMqb+jw26uoJ+TzwummSW9aOmk9hjw+o861mYSsff7OZ/SlhLwOyhllmjUyHuskTWethtOr8TH/qQj6PTuVUVqHKX7ejHma1LsDi1iBOjI9OqtOj0PnRBVO7QqpZ/ID10KTzJjYvb8U9u08AKJUSaAl60Rn24cREFgGvq+yhcbkIN196FgDLAvO4SN+cCmWBP1fh6vG6CQVT6DhEumBOK76VdIStoJdRLGJdbwyHR9KlAna24OX1mxbj+k1WLfb2sA8HZHmdxW1B3Y7phu1qiUpt8YfKz/k5i1t01UdFpmDC53bB43YhFiT43K6ytZYPDCaRypta+MvXbwWelsFyVegMsGI3gBVcHMyWxwuUxdylA5Zx7QcO+ko1fuwZQNOhMqGOjaZ1+yoF3Y7dWKomxJ96w9l4z0XL4ZGC75EjTqMo0Bby6jIRipYyi9+6tr0tAQwnrbr5Hrc14SoS8NScqVuJXVRVR/ov7zp/2u9F/G6kcoY+j7WKtCnsln1QTtb83vteqevsVKM97MPx8UyZO0i5FVWcrPLeaxaOtPhzhaJ2l9SD8mempvC7V8N+gdf2RPC5t5yDt8gFI+woy0ZZ3otagsgWLGu+MtgGlB7AbKGIUTkTs9boI+hzozcWwLL2kB5FqFICsaBHjxQ6p5gG73YRFrUG0T+WgRACn757L548OoaJTEF2CBntKhhJ5fQM5lyhiGyhKN0tjdkYHRE/ckYRA/GctiDVilnpvImIf/J5qcycUJb4dNabWqKy0tWjOGdRC46NZnBkJKUzVDK2iWEqH1stOBLPGNgtXTmbpGsj7PcgKoPR3VE/8kYRnRHfJNcEYI2UKheisbt6AKvjUWId9nmki2fqYH8lLUGvTAVN1Qzu2rELf7X7vycWwNaV7WXblJFSGdcCLJGzW/weF2mrWJXw6Ir6p3TRVOJykb7eqr0e2UFPRdhnuXpKFv/U96tbxoasz1r7eeWqDu0dqIZ6z95pqo62ZPGz8DeNnFE+m3M6lIAnc0ZNcaj+vdIF9nlcePcrl0+aLQxYN2ZH2KdT69RNf2IiU3U/AW+5xV+t1Kwi6HVjUWtAZ9U8eXRMP+TRgFd/dzqhWNIWRP9YGomcge8+egQ/230COaOoA3AqMyiRNfRwPWeYumBao64eewCvr8Wy3uOZwpSpuHZ3V8jr1sdUj/CXWfyVwi8rMl7297/CdV95GMDklD97eycyBew+NoFYwIOVtkyS7pgfKzrDOqBrT0cFyjt0VTxNBUrbZXDXfp2UIAZ9lgsmZxQnLVQyHSs6QnhpOKUNmrot/jpTodUoptoIpCXoRc4oIlsw9aQztX81Ie9j16zT6af1op67oK/+Zzwig7vpBu5XncLprTct3FfWPqDUgSqLv1oH2QwcKfyNBnfVTT5VGYVq2IedvmksjkW2ssQqA+TEeHbS5C2g3Mc/lsrrjI9qvO/VK/G+V6/Eq1Z3IOr34Od7TtoyOEqzZLumEQpL+DM6C0ONTl65ysq1Vm6OZM5Aa8hnrSZlFPXQuVHhf93GHt2pLGoNIBawrEO16Eq16ozK4g94LQuvyyaMUxGUrp7xjLXKVeUw375Km31Cmf1z9oyoeKaAo6MpnNUdKfMr/8nV63DrlWu0YC+bJPyl1NLj4xn43C6cK8+Bshb9HrfumJTFb193oRGLH7CC4IeH00hkjarxJDv2452qg7BTsvgn36P2QobJnImI36MNIyX8V2/owWvWNBbkVBZ1I6N6FdzVrp467lc1iauezwIld53d4m+RLuOS8LPF3zQaDe76PW743BWZNnW4euxi55smffSzMsfc53HpTqW2q8dm8afyU/pz375lKa49pw9+jxtXb+zB/zx7Sk9Gi9nq4kxv8YcwmCgVzFIljtf1RNES9OI5afGryT1+jzXXoN6hcyXRgBd333IJfviBi/GGc/sQC3oRzxqlpeuqWfzKovKp6odSGKe51mrGbDxTQEvQN8nl1Rb26WwU9dBmKoyHjgqLfziRn2R1v+G8Plyxvlufa7t/3/7b8UwBJ8az6GsNaAG0X2PVcVSOaNIFE8PJHAJeV90xlZUdYZyKZzEQz057T9tHyfUGW6cSfnW9hhI5afG7taFjN4QaJdygIFvf8SCVqz+4C1j3mceWkjwd6lmLVLH4VTZaPZ6E2cChwm9WzTGeirDfjWS25OqpJ7hrH9JNZUkBwPnL2vDUp6/Gz299ddmNofzldvz2dM50Xlvt0/HG8/oQzxq6VIO9EuZ0rgH1vgpAq5miLUEv1vdGSxa/nFXr97qQK9hcPXXklVfichG2rmyXAVSr/IUqpFXN4lRCovZVEsapr5UqjjaRKWgLrJKffOhV+Ohr1yCZM2CYlnuimqvHRVYsYniKKpK1LP7l0i300nAK/WNpLJL1guzHZj+uksUvO6O8oYuY1RsMVWmvO4+MTTuKLbf46xModa9WM05UueqDQ0mk8parR937KnA9E1TH39Co3u9GXi54A9Qn/CGfu6HO5a3nL8Ffv/mcsjiAOucnJqzqoc0oyFYNx2b1NHqCIwFPmaunUR9/PR1Nm6z0OWGbGfyOC5dO+pw933ssVZgyoGRni8zN33nYCjy2BD11W/xKeOwLwwNWB3h2Xww/3HkMxaLQs2r9Hle5q+c0b+hYwIPxTAEPPjcIn8els2WqtbFk8dfp6rHl8de6rkSkrbNkzpi0PJ9y9ayUS2nmzWLNzlRb/BXC3xbyoiXoxaHhFPYPJPGW8xfjuvP6kMobes0HoNRxdFda/HkTw8nJI42pUJOa+scyum5RLfwzcfXIe7Wa8KtCfS8OJHSm1uXrunFsLF3V4KkX1XlMl5ljp7K4Wz3JCGG/pyEXZm9LAO+5aHnZNr/HBZ/bZU3ynKNUTsCxFn+xoeAuAERkcSwVGK1nqBtuwNVT9j2bdVytsJSyouKy9ny9Fn8s4EU04NEzGa3gbn3CrzqIQxUzWFuCXpzdF7VKCwwnkTOKiPpLrh6Vn92oq6eSs/ti2Ht8Aj95qh+Xr+2qanG2VwTPKoWxFtrHn64t/EDJOotnjEk+/uUdYRBZ8x+sNFagq8bcileu6sAFy9uwcXH5ZCQiwqquMB7eP4RkzsD6vigifg9+75KVZRZ8pcWvOrZUztQLldTLcpkx5SLgva9aMeVnZ9vHrwr1vTiQtFw9Pg/OXdKCL9zwikmFEhtBXf9GjDv1HRUjqcdQiVSUZ54JRKS9B3Pl3wccK/zmtK6XSiLS1RPPWJbJdOlhQHmJ1kaEf0VHGK/b2INf/NFrqr6vbmiVWlivxQ9YvnpVdCwW8GLT0lZctrYLm23lnKuhLf6KBV1iAa+uIPiEHElE/MriL1VWnImrx84HLl2FkNeN8XRB18qv1UYl9Bv6YuiK+qespwRYVmmmMLXFD5SqpMazBTmtv3RMV63vxgN/cllZSYJalvfaniju+tCrqvrUV3VGtL+3VkneNbKInlrxTbt6CoZVtriB9MdowIvFrUG8bmPvpBFIJcpYcrsmB8Br4fe4p3RhrO2JYv9AAuPpwqytNDXTrB6gtBh9PS6cD1+xWsfmTgd1H8yVfx9wqKsn12BwF7BujOFkHhOZQtVMm6rfaSCrx07A68Y3fmfLFO9bv6VS/mpN3qrGkrYgnjsZh9dNMv/fj22/P/1692pkULm+ayzo1Z2gWi4vEvBKH3+xoWDZlPuP+PGnr1uHf9l+QJd1qKTS1bO0PYQnPvXaaX876HUjbxStWilTnEtt8WcLyFa4elwuwlldkbIqpvVm1thRfm+gvDKmnRs2L8G15/Tqe1iNLBNZA6PpfEMWPwD86IMX15WlpsQw4q9/QpXf45oy+WBNT1QvWG8vynY6qHo9M3H1DMlV0epxzdo7+dMhKs/9XFr8TRN+IgoAeAiAX+7nx0KIvySilQC+D6ADwC4AvyOEmLygbZMwiwJ5cwaunoAXR0bSVdfArUVwhq6e6VCjlZOyaFq1dURroYKFqgpmvcQC1iItBbNUgtnndmkfpYtKa9hGmuDqAYCbXrUCv3vx8prtDnit8gWNji6UMCVzxpTXVllm8YwhV2mavB970L8RX7tCLcy+rD1U053oclHZaEG1w5pgh4YsfqD+DBqVHllvRg8AbFraOuVsVFXCORbw4M2bJk9unAkzcfWozmIokUPIV3/HNhsoQ3Kh+PhzAK4UQrwCwCYA1xLRRQA+D+DLQojVAMYAvK+JbZjcKFk/pnGL323VyM/UL/w+KYpAfRZEvXjdBBfZLP6GXD1yicM6Ry0Kl4v0ftSQNBa0HhCXi9AW8ulFtMtcPbNk8SumeyB/e8tSXLm+u6HftH9+quF21O7qqbD4q32/UQEGgFXSLbW+hrVfDdWpqtFYoxZ/vagOppF75yNXrcGXfntTzffVBLUbL1zaUIbMVMwkuKvO4VAyN2vtqJfYPFj8zVxsXdgWUvfKfwLAlQB+LLdvA/DmZrWhGmqFo0bKMgNyZl/W0EsU1ouyPmfT4iciBLxuXXveXtp3OvSi5jPwJyp3z1nSHWH/jbawT5dEtmf1pPImvO761z44XT7zWxvxxvMWNfSdpe2hsqqItVDHO5G2yl5UMx7U9xvJpbezvCOEkM+tSz3Ug+pUVcfbFW2O5aiMl0aNhqlY3R3BP71jEz7S4OzcqZiZxW99ZzxdmDUjpV60j38hCD8AEJGbiHYDGARwP4CDAMaFECpfsR9A1fEdEd1MRDuJaOfQ0NCstUmtXNW4xe9FpmDi2GhGF7eqB+Vvnk3hB6z2G0WBgNdV15wCxRI5aaieCWiV2AuFtYd9Zb/RHvbpTlW7egpFWZnzzA8lXS6rRhYrlk+0E/V7QAQ9ia2qqydQWndhJu6CgNeN+/740mlTK+34PZarTS243ogh0AiWweGqO4e/3t+8ftPiGd2PtVAutkYsaHtguXJiXbPRWT1z6Opp6hMphDABbCKiVgA/BbC+ge/eBuA2ANiyZUvtp7FBZiz8gdKMzSUN3BgqNdPvnl0rQo1YemKBhgSmZPE3fumV8FsLiwT06lcAylJKowE5gcswkapjNaMzgb9400YQkV5vuBouFyHi9+g1B6q5EtSoYCaBXUUj9xdgiWfIZ7XLRdDZPs0g0ECJ5PniyvXduOtDF+sJcfVgT6Fu1FV4uqhOb0EEd+0IIcaJaDuAiwG0EpFHWv1LAExe166JaFdPw3n8pRtjSQMWf6hJFr+aTNPoCj0tQS+ifg9aZmBdKHFvDXnx+bedW9Z5li8tVz6B6+Ug/O1hH75846ZpPxcLePUC5dWEP+B1w+9xzSiwezoEfW4kc4YsaNe8gfwlZ3XqVdLOVNwuwgXL26f/oA17evdVZ8+x8Csf/0JI5ySiLgAFKfpBAFfDCuxuB3ADrMyemwDc06w2VEOtsOOfgatH0Yjwh5vg4wdK/tbKBT6mg4jwL+/ejOXT5GxXQ5V3aAl5cd6S1rL3VKdAZPmcS7V6Xh6unnqJBjwYjE+d672iI1x1wZ1mojrXRtyQM+Gr797c1N8/E2hkpDAbKMFvZD7O6dLMJ7IPwDYicsOKJfxQCPFfRLQPwPeJ6K8BPAXgW01swyS0q6fRCVy2gFZDrh5ZyOl0ZiJWQ1nbMxnWz3RJN1X2uJov0l55kIgsi79guXrmOkuimcSCXjwrV+OqlTVy1y2vamjexmygOtclp1HczOnccMESnWU0l1y9oQd/f8N5DWVynS5NE34hxB4Ak5a+EUIcAjD9jKEmkTtNV0804Glohl3Y75l1ax8otb9ZizFXw+7qqaRdujZUuWTLx2+5ejprlC54ORILePWSiLUyo+bDB64s/kZGo0w5//D2V8zLfgNeN96+ZXJNrmbiuJINKo+/8ZIN1kPeaOCtNeSd1fQ3RUD7+OfOl6yqSS6uYlWqTkGNjPweK+sokS0sKFePCopH/Z6qheLmi7ly9TALg4XzRNbJjIO7UtAatahuuXw13rZ5SUPfqYeZ+vhPh3MWt+DXH7+8qg9UzX5V1q5q39g85EU3E5Wee+XZ3U0Zyc0U5XZq1DBhnIkDhX+G6Zy+mQl/V9R/Wql9tQjMMKvndKkV+NKLTMjUNCX8E5mFJfxqiclrNvTOc0vKUXno7Oph6uHMMVnmiJkKfzTgwUWr2vGaNZ3NaFbDqOD0XAt/LUoWv5y3YDu/jS60fibz7ouWAQAuXXtm3AeKoM8NouoL9zBMJQvniayTrDEzV4/LRfj+zRc3o0kzYklbEGd1hc8Yd4PP40Is4EHUX27xAzObLHamcv2mxbh+loqJzSaXre2CEOKMuR+YM5uF80TWyUzTOc80brliNf7g0lXz3YwyPv+287BS1vGxB89fddaZZR0vRF63sRev23hmuZ+YMxcHCn/RKiM8y3n1c43bRXC7zqzO6/XnlhZIsVv8581S3XKGYWYHx40LswVTrwPKNJ91PdGXfSfLMAsNxylgbgYLrTONo2b5fuCyM8sdxTCMQ109jQZ2mcbZvKwNj/35VWdM1hHDMCUcp4DZgvmyD+y+XGDRZ5gzE8cJf94ocsobwzCOxnEKaBQFPHNcOZFhGOZMwnEKaBSL8HCWCcMwDsZ5wm8KFn6GYRyN84S/KOBxs/AzDONcHCn8bpfjDpthGEbjOAU0i0V42dXDMIyDaZrwE9FSItpORPuI6Fki+iO5/TNEdJyIdst/1zWrDdUwTDHr698yDMO8nGjmzF0DwMeEEE8SURTALiK6X773ZSHEPzRx37UbVRTwcjonwzAOppmLrZ8EcFK+ThDRcwDmvZC5WWSLn2EYZzMnpi8RrQBwPoDH5KY/JKI9RHQ7EbXV+M7NRLSTiHYODQ3NWlsKJufxMwzjbJou/EQUAXAXgI8KIeIAvgbgLACbYI0Ivljte0KI24QQW4QQW7q6umatPSanczIM43CaKvxE5IUl+ncIIX4CAEKIASGEKYQoAvgmgK3NbEMlBZPTORmGcTbNzOohAN8C8JwQ4ku27X22j70FwN5mtaEaJpdsYBjG4TQzq+cSAL8D4Bki2i23/TmAdxLRJgACwGEAH2hiGybBM3cZhnE6zczq+Q2Aagr782btsx64Vg/DME7Hcc5uk8syMwzjcByngFyWmWEYp+Mo4S8WBYoCPIGLYRhH4yjhN4oCALhkA8MwjsZRCmgUiwDY4mcYxtk4TPgti599/AzDOBlHCb9psvAzDMM4SvgLytXDPn6GYRyMoxTQVMFdtvgZhnEwjhJ+Q7p6OLjLMIyTcZbwq+Au1+phGMbBOEr4Tenj93BZZoZhHIyjFLDAWT0MwzD1Cz8RBYloXTMb02xUcJd9/AzDOJm6hJ+I3gRgN4B75d+biOhnTWxXU+CSDQzDMPVb/J+BtUTiOAAIIXYDWNmUFjURw+SSDQzDMPUKf0EIMVGxTcx2Y5oNZ/UwDMPUvwLXs0T0LgBuIloD4FYAO5rXrOZg6lo97OphGMa51KuAHwGwEUAOwH8AmADw0am+QERLiWg7Ee0jomeJ6I/k9nYiup+I9sv/206j/Q1RYFcPwzDM9BY/EbkB/LcQ4goAn2rgtw0AHxNCPElEUQC7iOh+AO8F8KAQ4u+I6JMAPgngE403vXF0yQZ29TAM42CmtfiFECaAIhG1NPLDQoiTQogn5esEgOcALAZwPYBt8mPbALy5kd89HQpcsoFhGKZuH38SwDPSYk+pjUKIW+v5MhGtAHA+gMcA9AghTsq3TgHoqfGdmwHcDADLli2rs5lTwz5+hmGY+oX/J/JfwxBRBMBdAD4qhIgTlaxtIYQgoqrZQUKI2wDcBgBbtmyZlQwitQIXZ/UwDONk6hJ+IcQ2IvIBWCs3vSCEKEz3PSLywhL9O4QQquMYIKI+IcRJIuoDMDiThs8Eg0s2MAzD1D1z93IA+wF8FcC/AniRiC6d5jsE4FsAnhNCfMn21s8A3CRf3wTgnsaaPHO0q4dn7jIM42DqdfV8EcA1QogXAICI1gK4E8AFU3znEgC/Ays2sFtu+3MAfwfgh0T0PgBHAPz2DNo9I3jNXYZhmPqF36tEHwCEEC9KN05NhBC/AVBLYa+qc7+zivLxc1YPwzBOpl7h30lE/wbge/LvdwPY2ZwmNQ/l4/dyVg/DMA6mXuH/EIAPwyrVAAAPw/L1v6zQFj9n9TAM42DqFX4PgH9SQVo5m9fftFY1CfbxMwzD1F+r50EAQdvfQQAPzH5zmovJ6ZwMwzB1C39ACJFUf8jXoeY0qXkUeAUuhmGYuoU/RUSb1R9EtAVApjlNah5msQiPi2CfPcwwDOM06vXxfxTAj4johPy7D8CNTWlREzGKgq19hmEcz5QWPxFdSES9QognAKwH8AMABVhr7740B+2bVQxTsH+fYRjHM52r5xsA8vL1xbBm3n4VwBhkAbWXE2ZRcLkGhmEcz3SuHrcQYlS+vhHAbUKIuwDcZSvD8LKhYBbZ4mcYxvFMZ/66iUh1DlcB+KXtvXrjA2cMJvv4GYZhphXvOwH8moiGYWXxPAwARLQa1rq7LyuMooCXXT0MwzicKYVfCPE5InoQVhbPfUIItSCKC9YC7C8rDLPIFj/DMI5nWneNEOLRKttebE5zmotRFLz6FsMwjsdRfg+zyOmcDMMwjhL+ging5pLMDMM4HEepoFkswsuuHoZhHI6jhJ9LNjAMwzRR+InodiIaJKK9tm2fIaLjRLRb/ruuWfuvBpdsYBiGaa7F/20A11bZ/mUhxCb57+dN3P8krOCuowY5DMMwk2iaCgohHgIwOu0H55BCscjpnAzDOJ75MH//kIj2SFdQW60PEdHNRLSTiHYODQ3Nyo45nZNhGGbuhf9rAM4CsAnASQBfrPVBIcRtQogtQogtXV1ds7Jzg9M5GYZh5lb4hRADQghTCFEE8E0AW+dy/0aRq3MyDMPMqfATUZ/tz7cA2Fvrs82ASzYwDMM0sbQyEd0J4HIAnUTUD+AvAVxORJsACACHAXygWfuvBqdzMgzDNFH4hRDvrLL5W83aXz1Y9fjZx88wjLNxlAoaXLKBYRjGYcJvcskGhmEYRwl/zijC73HPdzMYhmHmFUcJf7ZgIuB11CEzDMNMwjEqaJhFGEXBFj/DMI7HMcKfNYoAwBY/wzCOxzEqmC2YAICAly1+hmGcjQOF3zGHzDAMUxXHqGBOu3rY4mcYxtk4RviVxc/BXYZhnI6DhJ+DuwzDMICDhD/HwV2GYRgADhL+rMHCzzAMAzhJ+NnVwzAMA8BRwi8tfg7uMgzjcBwk/JzOyTAMAzhK+HkCF8MwDOAk4Tc4j59hGAZoovAT0e1ENEhEe23b2onofiLaL/9va9b+K1GuHr/HMX0dwzBMVZqpgt8GcG3Ftk8CeFAIsQbAg/LvOSFXMOHzuODiFbgYhnE4TRN+IcRDAEYrNl8PYJt8vQ3Am5u1/0qyBRMBtvYZhmHm3MffI4Q4KV+fAtBT64NEdDMR7SSinUNDQ6e942yhyBk9DMMwmMfgrhBCABBTvH+bEGKLEGJLV1fXae8vZ5gs/AzDMJh74R8goj4AkP8PztWOLYufXT0MwzBzrYQ/A3CTfH0TgHvmasdZtvgZhmEANDed804AjwBYR0T9RPQ+AH8H4Goi2g/gtfLvOcEK7rLwMwzDeJr1w0KId9Z466pm7XMqsoUiooGmHS7DMMzLBsc4vbMFdvUwDMMADhL+nMHpnAzDMICDhJ8ncDEMw1g4RgmzBRN+TudkGIZxkvAXOauHYRgGDhF+IQTn8TMMw0gcIfx5swgheBEWhmEYwCHCz8suMgzDlHCE8Ofksot+Fn6GYRhnCL+2+Dmdk2EYxhnCn5EWf9jPJRsYhmEcIfzJnAEACPnY1cMwDOMI4U/nLeFni59hGMYhwp/KWa4etvgZhmEcIvza4vexxc8wDOMI4U/lObjLMAyjcIbw55SPn109DMMwjhD+dM4AEbhIG8MwDJq49OJUENFhAAkAJgBDCLGlmftL5U2EvG64XNTM3TAMw7wsmE+n9xVCiOG52FE6byDE/n2GYRgADnH1pHImwpzKyTAMA2D+hF8AuI+IdhHRzdU+QEQ3E9FOIto5NDR0WjtL5QzO6GEYhpHMl/C/WgixGcDrAXyYiC6t/IAQ4jYhxBYhxJaurq7T2lkqb3AOP8MwjGRehF8IcVz+PwjgpwC2NnN/6byJEKdyMgzDAJgH4SeiMBFF1WsA1wDY28x9pnJs8TMMwyjmQw17APyUiNT+/0MIcW8zd5jOm1ynh2EYRjLnwi+EOATgFXO5Tw7uMgzDlFjw6ZxCCKTyJpdrYBiGkSx44c8ZRZhFgRD7+BmGYQA4QPjTqjIn+/gZhmEAOED4VWVOLtnAMAxjseCFX1n8ERZ+hmEYAA4Qfl5onWEYppwFL/y80DrDMEw5C174eaF1hmGYcha88I+l8wCAWMA7zy1hGIY5M1jwwv/8yTjCPjcWtwbnuykMwzBnBAte+PedjOPsvhgvu8gwDCNZ0MJfLAo8dzKBDYti890UhmGYM4YFLfxHR9NI5gxsZOFnGIbRLGjh33cyDgDY0Ncyzy1hGIY5c1jQwv/siQl4XIQ1PZH5bgrDMMwZw4IW/qVtIbx182IEvJzDzzAMo1jQ01nfsXUZ3rF12Xw3g2EY5oxiXix+IrqWiF4gogNE9Mn5aAPDMIxTmY/F1t0Avgrg9QA2AHgnEW2Y63YwDMM4lfmw+LcCOCCEOCSEyAP4PoDr56EdDMMwjmQ+hH8xgGO2v/vlNoZhGGYOOGOzeojoZiLaSUQ7h4aG5rs5DMMwC4b5EP7jAJba/l4it5UhhLhNCLFFCLGlq6trzhrHMAyz0JkP4X8CwBoiWklEPgDvAPCzeWgHwzCMI5nzPH4hhEFEfwjgfwC4AdwuhHh2rtvBMAzjVEgIMd9tmBYiGgJwZAZf7QQwPMvNOdPhY3YGfMzO4XSOe7kQYpKv/GUh/DOFiHYKIbbMdzvmEj5mZ8DH7ByacdxnbFYPwzAM0xxY+BmGYRzGQhf+2+a7AfMAH7Mz4GN2DrN+3Avax88wDMNMZqFb/AzDMEwFLPwMwzAOY0EKv5Pq/RPRYSJ6hoh2E9FOua2diO4nov3y/7b5bufpQES3E9EgEe21bat6jGTxFXnt9xDR5vlr+cypccyfIaLj8lrvJqLrbO/9mTzmF4jodfPT6tODiJYS0XYi2kdEzxLRH8ntC/ZaT3HMzb3WQogF9Q/WbOCDAFYB8AF4GsCG+W5XE4/3MIDOim1fAPBJ+fqTAD4/3+08zWO8FMBmAHunO0YA1wH4BQACcBGAx+a7/bN4zJ8B8KdVPrtB3ud+ACvl/e+e72OYwTH3AdgsX0cBvCiPbcFe6ymOuanXeiFa/Fzv3zrebfL1NgBvnr+mnD5CiIcAjFZsrnWM1wP4jrB4FEArEfXNSUNnkRrHXIvrAXxfCJETQrwE4ACs5+BlhRDipBDiSfk6AeA5WCXbF+y1nuKYazEr13ohCr/T6v0LAPcR0S4iullu6xFCnJSvTwHomZ+mNZVax7jQr/8fSrfG7TYX3oI7ZiJaAeB8AI/BIde64piBJl7rhSj8TuPVQojNsJay/DARXWp/U1jjwwWds+uEY5R8DcBZADYBOAngi/PamiZBRBEAdwH4qBAibn9voV7rKsfc1Gu9EIW/rnr/CwUhxHH5/yCAn8Ia9g2oIa/8f3D+Wtg0ah3jgr3+QogBIYQphCgC+CZKQ/wFc8xE5IUlgHcIIX4iNy/oa13tmJt9rRei8Dum3j8RhYkoql4DuAbAXljHe5P82E0A7pmfFjaVWsf4MwC/KzM+LgIwYXMTvKyp8F+/Bda1BqxjfgcR+YloJYA1AB6f6/adLkREAL4F4DkhxJdsby3Ya13rmJt+rec7qt2kSPl1sKLjBwF8ar7b08TjXAUrwv80gGfVsQLoAPAggP0AHgDQPt9tPc3jvBPWcLcAy6f5vlrHCCvD46vy2j8DYMt8t38Wj/m78pj2SAHos33+U/KYXwDw+vlu/wyP+dWw3Dh7AOyW/65byNd6imNu6rXmkg0MwzAOYyG6ehiGYZgpYOFnGIZxGCz8DMMwDoOFn2EYxmGw8DMMwzgMFn5mQUNEpq3C4e7pqrUS0QeJ6HdnYb+HiahzBt97HRF9Vlak/MXptoNhquGZ7wYwTJPJCCE21fthIcTXm9iWengNgO3y/9/Mc1uYBQpb/IwjkRb5F8hay+BxIlott3+GiP5Uvr5V1knfQ0Tfl9vaiehuue1RIjpPbu8govtkTfV/gzW5SO3rPXIfu4noG0TkrtKeG4loN4BbAfwjrGn6v0dEC3LWOTO/sPAzC51ghavnRtt7E0KIcwH8CyyxreSTAM4XQpwH4INy22cBPCW3/TmA78jtfwngN0KIjbBqJi0DACI6G8CNAC6RIw8TwLsrdySE+AGsyox7ZZuekfv+rZkfOsNUh109zEJnKlfPnbb/v1zl/T0A7iCiuwHcLbe9GsDbAEAI8Utp6cdgLZzyVrn9v4loTH7+KgAXAHjCKsuCIGoXzVsL4JB8HRZWfXaGmXVY+BknI2q8VrwBlqC/CcCniOjcGeyDAGwTQvzZlB+yls3sBOAhon0A+qTr5yNCiIdnsF+GqQm7ehgnc6Pt/0fsbxCRC8BSIcR2AJ8A0AIgAuBhSFcNEV0OYFhY9dMfAvAuuf31ANTCGQ8CuIGIuuV77US0vLIhQogtAP4b1gpLX4BVcG8Tiz7TDNjiZxY6QWk5K+4VQqiUzjYi2gMgB+CdFd9zA/geEbXAstq/IoQYJ6LPALhdfi+NUrngzwK4k4ieBbADwFEAEELsI6L/C2uVNBesapsfBnCkSls3wwru3gLgS1XeZ5hZgatzMo6EiA7DKuM7PN9tYZi5hl09DMMwDoMtfoZhGIfBFj/DMIzDYOFnGIZxGCz8DMMwDoOFn2EYxmGw8DMMwziM/w90QUij0WNJQQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ddpg(n_episodes=250, max_t=10000, print_every=100):   \n",
    "    scores_deque = deque(maxlen=print_every)\n",
    "    scores = []\n",
    "\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        \n",
    "        states = env.reset(train_mode=True)[brain_name].vector_observations     # reset the environment    \n",
    "        agent.reset()\n",
    "        \n",
    "        scores_episode = np.zeros(num_agents)               # rewards per episode for each agent\n",
    "        \n",
    "        for t in range( max_t ):\n",
    "            actions     = agent.act(states)\n",
    "            env_info    = env.step(actions)[brain_name]     # send all actions to tne environment\n",
    "            next_states = env_info.vector_observations      # get next state (for each agent)\n",
    "            rewards     = env_info.rewards                  # get reward (for each agent)\n",
    "            dones       = env_info.local_done               # see if episode finished\n",
    "            \n",
    "            for (state, action, reward, next_state, done) in zip(states, actions, rewards, next_states, dones):\n",
    "                agent.step(state, action, reward, next_state, done)\n",
    "            \n",
    "            \n",
    "            states = next_states\n",
    "            scores_episode += rewards\n",
    "            \n",
    "            if any(dones):\n",
    "                break \n",
    "                \n",
    "        \n",
    "        #Averaring the mean score across all agents for this episode\n",
    "        mean_score = np.mean( scores_episode )\n",
    "\n",
    "        scores.append( mean_score )\n",
    "        scores_deque.append( mean_score )\n",
    "        \n",
    "        \n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean( scores_deque )), end=\"\")\n",
    "        torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "        torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean( scores_deque )))\n",
    "            \n",
    "    return scores\n",
    "\n",
    "scores = ddpg()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 36.87799917571247\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions     = agent.act(states)                    # select an action (for each agent)\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future improvements\n",
    "\n",
    "In order to acheve better training stability, or even to understand how other algorithms works, some points that i would like to test in the future are:\n",
    "\n",
    "### Testing A2C and A3C\n",
    "\n",
    "As was stated in the classes some researchers may not consider DDPG, used for this solution, as an \"Actor-Critic\" in the strict form and, for knowledge, i would like to understand how would be the performance of the Multi-agent DDPG compared to A2C ad A3C methods. \n",
    "\n",
    "### Hyperparemeters Episode-based scaling.\n",
    "\n",
    "As far as i understood adding the random components to the network output allows it to \"explore\" and to diversify it's output and make the Critic more aware of different scenarios which will, eventually, lead to a better exploration of the \"state-space\".\n",
    "\n",
    "As the network progresses training, and this could be evaluated using episodes or even it's score, maybe it would make sense to reduce the noise magnitude added to make it smaller as the training progresses. My suggestion that needs to be proven by data and testing is that this could lead to faster convergenge or, at least, better reaching the network local-m√°xima, increase it's score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
